<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[打造基于git的跨平台密码管理器]]></title>
    <url>%2F2019%2F02%2F15%2FInstrumentalism%2Fbuild-more-secure-pass-manager%2F</url>
    <content type="text"><![CDATA[现在互联网的发达程度，导致我们对需要管理并维护很多属于自己的账号信息。很多人为了自己方便起见，将自己的所有账户的密码设置为同一个。这样虽然方便，但一旦一个账户的密码泄露，所有的账号都会被一锅端。因此密码管理工具应运而生。 当前最流行的密码管理工具应该就是1Password与LastPassword。然而作为商业软件，这种软件不仅仅需要付费使用，同时用户需要完全信任这种软件运营开发公司，由于其代码封闭，难以审计，很难说在你将自己的密码交给他之后会被做什么。 因此，结合现有的开源方案，在这里提出一套可以媲美1Password等商业方案的密码管理解决方案。 总体来说这套方案适用于如下需求： 希望免费拥有一套免费密码管理方案； 不信任1Password，LastPassword这种中心化密码管理方案； 有一定的技术能力。 使用工具 这套方案需要使用如下几个工具相互配合来实现： git - 分布式版本管理软件，用于管理加密后的密码库，同时负责跨平台的同步密码库。 pass - 管理并组织密码库的软件，提供多种跨平台客户端。 gunpg - OpenPGP的实现，负责加密认证密码库。 github - 作为密钥库存储的中央仓库，github现在提供免费的私有仓库，也可以采用其他的托管仓库。 ## 安装与配置 由于不同操作系统之间的差异，因此在安装、配置的时候需要根据不同的操作系统区别进行。 首先需要拥有一个github仓库或者其他支持git协议的托管仓库。 Linux 区别于不同的发行版，Linux可以选择并采用不同的方式去安装软件。需要安装的软件包括如下： pass - 原始版本的pass密码管理器 gnupg2 - GPG2，必须 git - 版本管理工具，必须 qtpass - 图形化pass密码管理器，与原始版本pass二选其一即可，也可以共存。 首先你需要创建一个gpg密钥，可以生成一个新的，也可以将你已有的gpg密钥导入当前电脑上。 如果你采用图形化密码管理器qtpass，参见Windows系统下的配置方法；如果采用命原始的pass密码管理器，首先需要初始化你的密码存储库： 1$ pass init "&lt;你的gpg公钥ID&gt;" 之后你可以利用git初始化这个密钥仓库 1$ pass git init 之后添加托管仓库 1$ pass git remote add origin &lt;仓库的远程地址&gt; Linux下默认的密码库会被存储在~/.password-store目录下。 Windows windows系统下可以避免在命令行下工作，使用图形化界面完成操作，除了git之外。 首先你需要下载并安装如下软件： gpg4win - windows上的gpg加密软件（可选图形化界面）； TortoiseGit - windows上的git软件（图形界面）； qtpass - 图形化pass密码管理器。 在安装好之后，首先配置git，如果你之前使用过git，并且完成过配置可以忽略此步骤； 之后使用gpg4win提供的图形化密钥管理软件Kleopatra生成或导入属于自己的gpg密钥； 使用TortoiseGit在需要放置密码库的位置初始化git仓库，并添加托管仓库的远程地址； 最后运行QtPass，在设置页面的用用户选项卡中设置密码库。 Android 安卓系统下使用，只需要两个软件即可，分别是： Password Store - pass密码管理器的安卓版，自带git版本管理； OpenKeyChain - gpg的安卓版本，管理私钥。 安卓上配置则较为简单，只需要生成或导入gpg密钥，同时在Password Store中配置远端托管仓库即可。 iOS iOS端可以使用pass-password-store来管理并同步属于你的密码。 生成密码 不同平台的采用的客户端不相同，则生成新密码的方式各不相同。pass将密码库中的密码以文件夹的形式进行管理，你可以自由的选择密码的组织方式。 pass 命令 如果你使用pass命令来生成新密码，则在shell中执行： 1$ pass generate Email/aliyun.com 15 这个命令会在Email目录下生成一个名为aliyun.com的文件，同时会在命令行输出一个长度为15的随机密码。整个文件会采用gpg加密存储。当然你需要在生成的时候输入gpg的口令。 在生成新密码之后，你需要手动使用git管理密码库： 123$ pass git add -A$ pass git commit -m "add password"$ pass git push -u origin master QtPass 如果你使用qtpass来进行图形化的管理，则只需要点击新密码按钮，之后生成你需要长度的密码，点击生成即可生成新密码。当你点下确认保存密码之后，QtPass会自动帮你管理提交密码库到远端托管仓库中。 Password Store Password Store可以非常轻易的创建新的密码，生成密码之后只需选择功能菜单中的git pull与git push就可以与托管仓库进行同步。 OTP OTP多用于两步验证过程，pass也是可以支持OTP，根据不同的实现，支持程度略有不同。pass命令需要安装otp扩展，Password Store可以直接支持，而QtPass则完全不支持。 在添加OTP时，网站上往往会给出一个二维码，这个二维码中记录了一个字符串，用于描述OTP的具体细节。在pass中使用时，由于pass管理的密码库本质上就是一个经过加密的文本文件，因此只需将二维码中的字符串写在文件中独立的一行即可。凡是可以使用谷歌手机验证器进行的两步验证都可以在pass中管理。 pass命令使用的扩展可以使用如下命令添加新的OTP： 12$ pass otp insert Email/aliyun.com # 创建一个新的密码文件用于记录otp，存储在Email/aliyun.com$ pass otp append Email/aliyun.com # 添加otp到密码文件Email/aliyun.com中 生成新的OTP码只需要： 1$ pass otp Email/aliyun.com Reference pass pass-otp GPG入门教程]]></content>
      <categories>
        <category>Instrumentalism</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gunpg</tag>
        <tag>password manager</tag>
        <tag>pass</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QUIC协议翻译 - draft-ietf-quic-transport-latest Part 2.]]></title>
    <url>%2F2019%2F02%2F14%2Fnetwork%2Fquic%2Fdraft-ietf-quic-transport-latest-2%2F</url>
    <content type="text"><![CDATA[本文是对QUIC协议IETF提案：draft-ietf-quic-transport-latest翻译的第一部分。 draft-ietf-quic-transport-latest是在draft-ietf-quic-invariants-latest基础上定义的第一个版本的QUIC协议，这里描述了QUIC协议的核心，包括一些概念定义与具体的协议行为。 第一部分翻译内容包括第4，5节。 4. 流量控制 为了防止发送方的速度过快从而导致接收者难以接受数据，或防止恶意发送方在接收方处消耗大量内存，有必要限制接收方可以缓冲的数据量，为了使接收方能够限制对连接的内存，并对发送方实施调控，流被单独地和作为聚合流控制。QUIC接收方控制发送方可以在流上发送的最大数据量，如第4.1节和第4.2节所述。 同样，为了限制连接中的并发性，QUIC端点控制其对等方可以启动的最大累积流数，如第4.5节所述。 在CRYPTO帧中发送的数据的流控制方式与流数据的流控制方式不同。 QUIC依赖于加密协议实现来避免过度缓冲数据，请参阅[QUIC-TLS]。具体的实现中应该为QUIC提供一个接口来告诉QUIC它的缓冲限制，以便在限制不同层次上过多的缓冲。 4.1 数据流量控制 QUIC采用类似于HTTP/2 [HTTP2]中基于信用分数（credit）的流控制方案，其中接收方通告它准备在给定流和整个连接上接收的字节数。这产生了QUIC中的两级数据流控制： 流级流量控制，通过限制可在任何流上发送的数据量，防止单个流消耗连接的整个接收缓冲区。 连接级流量控制，通过限制所有流上STREAM帧中发送的流数据的总字节数，防止发送者超过接收者的连接缓冲容量。 接收方通过在握手期间发送传输参数来设置所有流的初始信用分数（credit）（第7.3节）。接收方向发送方发送MAX_STREAM_DATA（第19.10节）或MAX_DATA（第19.9节）帧，以通告增加的信用分数（credit）。 接收方通过发送MAX_STREAM_DATA帧并适当地设置流ID字段来通告流的信用分数（credit）。MAX_STREAM_DATA帧指示流的最大绝对字节偏移量。接收方可以使用当前消耗的数据偏移量来确定被通告的流量控制偏移量。接收方可以在多个数据包中发送MAX_STREAM_DATA帧，即使其中一个数据包丢失了，也可以确保发送方在消耗完流控制信用分数（credit）之前收到更新。 接收方通过发送MAX_DATA帧来通告连接信用分数（credit），该帧指示所有流的绝对字节偏移之和的最大值。接收方维护在所有流上接收的累积字节总和，用于检查流控制违规。接收方可以使用所有流上消耗的字节总数来确定要通告的最大数据限制。 接收方可以通过在连接期间的任何时间发送MAX_STREAM_DATA或MAX_DATA帧来通告更大的偏移。但是接收方不能背弃通告的值。也就是说，一旦接收方通告了一个偏移量，它再通告对方一个较小的偏移量则不会产生效果。 如果发送方违反被通告的连接或流数据量限制，接收方必须用FLOW_CONTROL_ERROR错误（第11节）关闭连接。 发送方必须忽略任何不提升流量控制限制的MAX_STREAM_DATA或MAX_DATA帧。 如果发送方用完了流量控制信用分数，它将无法发送新数据并被视为已被阻塞。发送方应该发送TREAM_DATA_BLOCKED或DATA_BLOCKED帧以指示它有要写入的数据但被流控制限制阻止。预计这些帧在常见情况下不经常发送，但它们被认为对调试和监视有用。 发送方在达到数据限制时应该仅发送一次STREAM_DATA_BLOCKED或DATA_BLOCKED帧。除非确定原始帧丢失，否则发送方不应为相同的数据限制发送多个STREAM_DATA_BLOCKED或DATA_BLOCKED帧。在数据限制增加后，可以发送另一个STREAM_DATA_BLOCKED或DATA_BLOCKED帧。 4.2 流量控制信用分数的增加 本文档将MAX_STREAM_DATA或MAX_DATA帧中通告的时间间隔和字节数量限制留给实现，但提供了一些注意事项。这些帧有助于降低连接开销。因此，经常发送具有小变化的帧是不被鼓励的。同时，如果更新频率较低，则需要更大的增量限制以避免阻塞，因此接收方需要提供更大的缓存资源。因此，在确定通告限制的大小时，在资源维护和开销之间存在折衷。（原文：Thus there is a trade-off between resource commitment and overhead when determining how large a limit is advertised.） 接收方可以使用基于往返时间估计和接收应用消耗数据的速率的自动调整机制来调整通告增加的信用分数的频率和数量，类似于常见的TCP实现。作为优化，仅当存在要发送的其他帧或者对等体被阻止时发送与流控制相关的帧确保流控制不会导致额外的数据包被发送。 如果发送方用完了流量控制信用分数，它将无法发送新数据并被视为已被阻塞。通常认为最好不要让发送方被阻塞。为避免阻塞发送方，并合理地考虑丢失的可能性，接收方应至少两次往返发送MAX_DATA或MAX_STREAM_DATA帧，然后才能阻塞发送方。 在发送MAX_STREAM_DATA或MAX_DATA之前，接收方不能等待来自发送方的STREAM_DATA_BLOCKED或DATA_BLOCKED帧，因为这样做意味着发送方将至少在整个往返过程中被阻塞，如果对等方选择不发送STREAM_DATA_BLOCKED或DATA_BLOCKED，则被阻塞时间可能更长。 4.3 处理流取消 端点需要最终就消耗的流量控制信用分数达成一致，以避免超出流量控制限制或死锁。 在接收到RESET_STREAM帧时，端点将取消对应流的状态计算并忽略到达该流的其他数据。如果RESET_STREAM帧与同一流的流数据重新排序，则接收者对该流上接收的字节数的估计可能低于发送者对发送的数量的估计。因此，两个端点可能无法就计入连接级流量控制的字节数达成一致。 要解决此问题，RESET_STREAM帧（第19.4节）包括在流上发送的最终数据大小。在接收到RESET_STREAM帧时，接收方明确地知道在RESET_STREAM帧之前在该流上发送了多少字节，并且接收方必须使用流的最终大小来实施连接级流量控制。 RESET_STREAM会终止流的一个方向。对于双向流，RESET_STREAM对相反方向的数据流没有影响。两个端点必须在未终止方向上继续保持流的流控制状态，直到该方向进入终结状态，或者直到其中一个端点发送CONNECTION_CLOSE。 4.4 流最终大小 最终大小是流消耗的流量控制信用分数。假设流上的每个连续字节都发送一次，最终大小是发送的字节数。更一般地说，这比流上发送的最大字节偏移大一。 对于重置的流，最终大小在RESET_STREAM帧中显式携带。否则，最终大小是偏移加上标有FIN标志的STREAM帧的长度，或者在传入的单向流的情况下为0。 当流的接收部分进入“Size Known”或“Reset Recvd”状态时（第3节），端点将知道流的最终大小。 端点不得在最终大小或超出最终大小的流上发送数据。 一旦知道了流的最终大小，它就不能再改变。如果收到RESET_STREAM或STREAM帧，指示流的最终大小发生了变化，则端点应该响应FINAL_SIZE_ERROR错误（参见第11节）。接收方应该将最终大小或超出最终大小的数据接收视为FINAL_SIZE_ERROR错误，即使在流关闭后也是如此。生成这些错误不是强制性的，只是因为要求端点生成这些错误也意味着端点需要维持关闭流的最终大小状态，这可能意味着需要维护一些状态。 4.5 控制并发 端点限制对等方可以打开的传入流的总数。只有流ID小于max_stream * 4 + initial_stream_id_for_type的流可以被打开。初始限制在传输参数中设置（参见第18.1节），随后使用MAX_STREAMS帧（第19.11节）公布限制。单向和双向流适用于不同的限制。 端点不得超过其对等端设置的限制。接收流ID超过其发送限制的STREAM帧的端点必须将其视为STREAM_LIMIT_ERROR类型的流错误（第11节）。 接收方不能违背通告。也就是说，一旦接收器使用MAX_STREAMS帧通告流限制，则通告较小的限制无效。接收方必须忽略任何不增加流限制的MAX_STREAMS帧。 与流级和连接级流量控制一样，本文档将通过MAX_STREAMS向对等体通告的时间间隔和流数量留给实现。实现可能会选择增加限制，以保持对等体可用的流数量大致一致。 由于对等端限制而无法打开新流的端点应该发送STREAMS_BLOCKED帧（第19.14节）。该信号被认为对调试很有用。在通告增加信用分数之前，端点不得等待接收此信号，因为这样做意味着对等体将至少在整个往返中被阻塞，并且如果对等体选择不发送STREAMS_BLOCKED帧，则可能持续更长时间。 5. 连接 QUIC的连接建立将版本协商与加密和传输握手相结合，以减少连接建立延迟，如第7节所述。一旦建立，连接可以迁移到任一端点的不同IP或端口，如第9节所述。最后，连接可以由任一端点终止，如第10节所述。 5.1 连接ID 每个连接都拥有一组连接标识符或连接ID，每个标识符都可以标识连接。连接ID由端点独立选择;每个端点选择其对等方使用的连接ID。 连接ID的主要功能是确保较低协议层（UDP，IP）的寻址更改不会导致QUIC连接的数据包传递到错误的端点。每个端点使用特定于实现（并且可能是特定于部署）的方法来选择连接ID，该方法将允许具有该连接ID的分组被路由到端点并在接收时由端点识别。 连接ID不得包含外部观察者可以使用的任何信息，防止将它们与同一连接的其他连接ID相关联。作为一个简单的例子，这意味着在同一连接上不得多次发出相同的连接ID。（原文：Connection IDs MUST NOT contain any information that can be used by an external observer to correlate them with other connection IDs for the same connection. As a trivial example, this means the same connection ID MUST NOT be issued more than once on the same connection.） 具有长标头的数据包包括源连接ID和目标连接ID字段。这些字段用于设置新连接的连接ID，有关详细信息，请参阅第7.2节。 具有短标头的数据包（第17.3节）仅包含目标连接ID，并省略显式长度。期望终结点知道目标连接ID字段的长度。使用基于连接ID路由的负载均衡器的端点可以在固定长度上与负载均衡器达成连接ID，或者就编码方案达成一致。固定部分可以编码显式长度，这允许整个连接ID的长度变化并且仍然可以由负载平衡器使用。 版本协商（第17.2.1节）数据包回应客户端选择的连接ID，以确保正确路由到客户端并允许客户端验证数据包是否是初始数据包的响应。 当路由不需要连接ID并且数据包的地址/端口元组足以识别连接时，可以使用零长度连接ID。对等体已选择零长度连接ID的端点必须继续在连接的生存期内使用零长度连接ID，并且绝不能从任何其他本地地址发送数据包。 当端点请求非零长度连接ID时，需要确保对等体具有连接ID可供选择，从中可以选择发送到端点的数据包。这些连接ID由端点使用NEW_CONNECTION_ID帧提供（第19.15节）。 5.1.1 发出连接ID 每个连接ID都有一个关联的序列号，以帮助对消息进行数据去重。在握手期间，端点发出的初始连接ID在长数据包报头的源连接ID字段（第17.2节）中发送。初始连接ID的序列号为0.如果发送preferred_address传输参数，则提供的连接ID的序列号为1。 使用NEW_CONNECTION_ID帧将附加连接ID传送给对等体（第19.15节）。每个新发布的连接ID上的序列号必须增加1.客户端在初始数据包中随机选择的连接ID和重试数据包提供的任何连接ID都不会分配序列号，除非服务端选择将它们保留为初始连接ID。 当端点发出连接ID时，它必须接受在连接期间携带此连接ID的数据包，或者直到其对等体通过RETIRE_CONNECTION_ID帧使连接ID无效（第19.16节）。 端点应该确保其对等体具有足够数量的可用和未使用的连接ID。虽然每个端点独立选择要发出的连接ID数量，但端点应该提供并维护至少八个连接ID。端点应该通过在对等体退出连接ID时或者当端点接收到具有先前未使用的连接ID的数据包时始终提供新的连接ID来执行此操作。启动迁移并要求非零长度连接ID的端点应该在迁移之前为其对等方提供新的连接ID，否则可能会使对等方关闭连接。 5.1.2 使用和退出连接ID 端点可以在连接期间随时将其用于对等的连接ID更改为另一个可用的连接ID。端点使用连接ID的响应来迁移对等体，有关更多信息，请参见第9.5节。 端点维护从其对等方接收的一组连接ID，其中任何一个都可以在发送数据包时使用。当端点希望从使用中删除连接ID时，它会向其对等端发送RETIRE_CONNECTION_ID帧。发送RETIRE_CONNECTION_ID帧表示将不再使用连接ID，并请求对等方使用NEW_CONNECTION_ID帧将其替换为新的连接ID。 如第9.5节所述，每个连接ID必须用于仅从一个本地地址发送的数据包。迁移远离本地地址的端点应该在该地址不再计划使用该地址时退出该地址上使用的所有连接ID。 5.2 将数据包与连接匹配 传入的数据包在被接收时分类。数据包可以与现有连接相关联，或者服务端会创建新连接。 主机尝试将数据包与现有连接相关联。如果数据包具有与现有连接相对应的目标连接ID，则QUIC会相应地处理该数据包。请注意，可以将多个连接ID与连接关联见5.1节。 如果目标连接ID为零长度且数据包与主机不需要连接ID的连接的地址/端口元组匹配，则QUIC将该数据包作为该连接的一部分进行处理。端点应该拒绝使用与现有连接相同的地址的连接尝试，或者使用非零长度的目标连接ID，以便可以将数据包正确地与连接匹配。 端点可以为任何无法与现有连接匹配的数据包发送无状态重置（第10.4节）。无状态重置允许对等方更快地识别连接何时变得不可用。 与现有连接匹配但端点无法去除数据包保护的数据包将被丢弃。 可以丢弃无数据包保护的无效数据包，例如Initial，Retry或Version Negotiation。如果端点在发现错误之前提交状态更改，则必须生成连接错误。 5.2.1 客户端数据包处理 发送到客户端的有效数据包始终包含与客户端选择的值匹配的目标连接ID。选择接收零长度连接ID的客户端可以使用地址/端口元组来标识连接。与现有连接不匹配的数据包将被丢弃。 由于数据包重新排序或丢失，客户端可能会收到使用尚未计算的密钥加密的连接数据包。客户端可以丢弃这些数据包，或者可以缓冲它们以预期以后允许它计算密钥的数据包。 如果客户端收到的数据包具有不受支持的版本，则必须丢弃该数据包。 5.2.2 服务端包处理 如果服务器收到的数据包具有不受支持的版本，但数据包足够大，无法为服务器支持的任何版本启动新连接，则应该按照第6.1节中的说明发送版本协商数据包。服务器可以对这些数据包进行速率控制，以避免版本协商数据包的风暴。 不受支持的版本的第一个数据包可以对任何特定于版本的字段使用不同的语义和编码。特别地，不同的数据包保护密钥可以用于不同的版本。不支持特定版本的服务器不太可能解密数据包的有效负载。服务端不应尝试解码或解密来自未知版本的数据包，而是发送版本协商数据包，前提是数据包足够长。 服务器必须丢弃包含不受支持的版本的其他数据包。 具有受支持版本或无版本字段的数据包与使用连接ID的连接匹配，或者使用（对于具有零长度连接ID的数据包）地址端口元组进行匹配。如果数据包与现有连接不匹配，则服务器继续执行下面的动作。 如果数据包是完全符合规范的初始数据包，则服务器继续进行握手（第7节）。这会将服务端提交到客户端选择的版本。 如果服务器当前没有接受任何新连接，它应该发送一个包含CONNECTION_CLOSE帧的初始数据包，错误代码为SERVER_BUSY。 如果该数据包是0-RTT数据包，则服务端可以缓冲有限数量的这些分组以等待迟到的初始数据包。在服务端响应之前，客户端被禁止发送握手数据包，因此服务器应该忽略任何此类数据包。 服务器必须在所有其他情况下丢弃传入的数据包。 5.3 QUIC连接的生命周期 TBD]]></content>
      <categories>
        <category>network</category>
        <category>quic</category>
      </categories>
      <tags>
        <tag>QUIC</tag>
        <tag>translate</tag>
        <tag>RFC</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QUIC协议翻译 - draft-ietf-quic-transport-latest Part 1.]]></title>
    <url>%2F2019%2F02%2F13%2Fnetwork%2Fquic%2Fdraft-ietf-quic-transport-latest-1%2F</url>
    <content type="text"><![CDATA[本文是对QUIC协议IETF提案：draft-ietf-quic-transport-latest翻译的第一部分。 draft-ietf-quic-transport-latest是在draft-ietf-quic-invariants-latest基础上定义的第一个版本的QUIC协议，这里描述了QUIC协议的核心，包括一些概念定义与具体的协议行为。 第一部分翻译内容包括第1，2，3节。 Abstract 本文档定义了QUIC传输协议的核心。随附文档描述了QUIC的丢失检测和拥塞控制以及使用TLS进行密钥协商。 1. 简介 QUIC是一种多路复用且安全的通用传输协议，它具有如下特性： 流复用 流和连接级控制 低延迟连接建立 连接迁移和弹性的NAT重绑定 经过加密与认证的包头和负载 QUIC使用UDP作为基础，以避免需要更改旧版客户端操作系统和中间件。 QUIC验证其所有包头并加密它交换的大多数数据，包括其信令，以避免引起对中间件的依赖。 1.1 文档结构 本文档描述了核心QUIC协议，其结构如下。 流是QUIC提供的基本服务抽象。 第2节 描述了与流相关的核心概念， 第3节 提供了流的参考模型， 第4节 概述了流量控制的操作。 连接是QUIC端点进行通信的主体。 第5节 描述了流相关的核心概念， 第6节 描述了版本协商， 第7节 详细描述了建立连接的过程， 第8节 明确关键的拒绝服务缓解机制， 第9节 描述了端点如何迁移连接到新的网络路径上， 第10节 列出了结束已经打开的流的选项， 第11节 提供了对错误处理的通用指导 数据包和数据帧是QUIC通讯的基础单元。 第12节 描述了数据包和数据帧相关的概念， 第13节 定义了传输，重传，和确认的模型 第14节 明确了管理数据包大小的规则 最后，QUIC协议元素的编码细节描述如下： 第15节 （版本） 第16节 （整数编码） 第17节 （数据包头） 第18节 （传输参数） 第19节 （数据帧） 第18节 （错误） 随附文档描述了QUIC的丢失检测和拥塞控制[QUIC-RECOVERY]，以及使用TLS进行密钥协商[QUIC-TLS]。 本文档定义了QUIC版本1，它符合[QUIC-INVARIANTS]中的协议不变量。 1.2 公约和定义 略 1.3 符号约定 本文档中的数据包和框架图使用[RFC2360]第3.1节中描述的格式，并附带以下附加约定： 12345[x]: 表示x是可选的x(A): 表示x有A bit长x(A/B/C): 表示x有A，B或C bit长x(i): 表示x使用第16节描述的可变长编码x(*): 表示x是可变长度的 2. 流 QUIC中的流为应用程序提供轻量级，有序的字节流抽象。 从另一个角度来说流是QUIC作为弹性的消息抽象。 可以通过发送数据来创建流。与流管理相关的过程（结束，取消和流控制）都旨在实现最小的开销。例如，单个STREAM帧可以打开流，携带数据或关闭流。流也可以是长期存在的，并且可以持续整个连接的持续时间。 流可以由任一端点创建，可以同时发送与其他流不同的数据，并且可以被取消。 QUIC没有提供任何确保不同流之间字节排序的方法。 QUIC允许任意数量的流同时运行，并且可以在任何流上发送任意数量的数据，受流控制约束（参见第4节）和流限制。 2.1 流类型与识别码 流可以是单向的或双向的。单向流在一个方向上传输数据：从流的发起者到对等方。双向流允许数据在两个方向上发送。 通过数值在连接中标识流，称为流ID。流ID对于流是唯一的。 QUIC端点绝不能重用连接中的流ID。流ID被编码为可变长度整数（参见第16节）。 流ID的最低有效位（0x1）标识流的发起者。客户端发起的流具有偶数编号的流ID（位设置为0），服务器发起的流具有奇数编号的流ID（位设置为1）。 流ID的第二个最低有效位（0x2）区分双向流（位设置为0）和单向流（位设置为1）。 因此，来自流ID的最低有效两位将流识别为四种类型之一，如表1中所总结的。 掩码 发起者 流类型 0x1 客户端发起 双向流 0x2 服务端发起 双向流 0x3 客户端发起 单向流 0x4 服务端发起 单向流 在每种类型中，使用数字增加的流ID创建流。不按顺序使用的流ID将会导致该类型的所有具有较低编号的流ID的流也被打开。 客户端打开的第一个双向流的流ID为0。 2.2 接收和发送数据 STREAM帧封装了应用程序发送的数据。端点使用STREAM帧中的Stream ID和Offset字段按顺序放置数据。 端点必须能够将流数据作为有序字节流传递给应用程序。提供有序的字节流要求端点缓冲任何无序接收的数据，直到宣称流量控制限制。 QUIC没有特别规定无序传输流数据。但是，实现可以选择提供将数据无序传递到接收应用程序的能力。 端点可以多次接收相同流偏移的流的数据。已经收到的数据可以被丢弃。如果多次发送，给定偏移量的数据不得改变;端点可以将流中相同偏移量的不同数据的接收视为PROTOCOL_VIOLATION类型的连接错误。 Streams是一种有序的字节流抽象，QUIC中不存在其他可见的结构。当数据传输，数据包丢失后重传数据或者数据在接收器传送到应用程序时，预计不会保留STREAM帧边界。【TODO】 端点不得在任何流上发送数据，而不确保它在同级设置的流量控制限制范围内。流量控制在第4节中详细描述。【TODO】 2.3 流优先级 如果分配给流的资源被正确地优先化，则流复用可以对应用性能产生显着影响。 QUIC不提供交换优先级信息的框架。相反，它依赖于从使用QUIC的应用程序接收优先级信息。 QUIC实现应该提供应用程序可以指示流的相对优先级的方式。在决定将资源专用于哪些流时，实现应该使用应用程序提供的信息。 3. 流状态 本节按发送或接收组件描述流。描述了两个状态机：一个是使用流传输数据时端点的状态机（第3.1节），一个是使用流接收数据时端点的状态机（第3.2节）。 单向流直接使用适用的状态机。双向流使用两个状态机。在大多数情况下，无论流是单向还是双向，这些状态机的使用都是相同的。打开流的条件对于双向流来说稍微复杂一些，因为发送侧或接收侧的打开导致流在两个方向上打开。 端点必须按流ID的递增顺序打开相同类型的流。 备注：这些状态机的信息很大。本文档使用流状态来描述何时以及如何发送不同类型的帧以及在接收到不同类型的帧时预期的反应的规则。虽然这些状态机旨在用于实现QUIC，但这些状态并非旨在约束实现。实现可以定义不同的状态机，只要其行为与实现这些状态的实现一致即可。 3.1 发送流状态 图1显示了将数据发送到对等方的流的一部分的状态。 123456789101112131415161718192021222324252627282930313233 o | Create Stream (Sending) | Peer Creates Bidirectional Stream v+-------+| Ready | Send RESET_STREAM| |-----------------------.+-------+ | | | | Send STREAM / | | STREAM_DATA_BLOCKED | | | | Peer Creates | | Bidirectional Stream | v |+-------+ || Send | Send RESET_STREAM || |----------------------&gt;|+-------+ | | | | Send STREAM + FIN | v v+-------+ +-------+| Data | Send RESET_STREAM | Reset || Sent |------------------&gt;| Sent |+-------+ +-------+ | | | Recv All ACKs | Recv ACK v v+-------+ +-------+| Data | | Reset || Recvd | | Recvd |+-------+ +-------+ 端点启动的流的发送部分（客户端类型0和2，服务器类型1和3）由应用程序打开。 Ready状态表示新创建的流，该流能够接受来自应用程序的数据。可以在此状态下缓冲流数据以准备发送。 发送第一个STREAM或STREAM_DATA_BLOCKED帧会导致流的发送部分进入Send状态。实现可以选择直到它发送第一帧并进入该状态时再将流ID分配给流，这可以允许更好的流优先级。 由对等方发起的双向流的发送部分（服务器类型0，客户端类型1）进入Ready状态时，如果接收部分进入Recv状态则立即转换到Send状态（第3.2节）。 在Send状态中，端点通过STEAM帧发送（在必要时重新发送 ）流数据。端点遵守其对等方设置的流量控制限制，并继续接受和处理MAX_STREAM_DATA帧。如果它被流量控制阻塞通过流或者连接发送数据，则Send状态的端点会生成STREAM_DATA_BLOCKED帧。 在应用程序指示已发送所有流数据并且发送包含FIN位的STREAM帧之后，流的发送部分进入Data Sent状态。从该状态开始，端点仅在必要时重传流数据。端点不需要检查流控制限制，也不需要为此状态的流发送STREAM_DATA_BLOCKED帧。可以接收MAX_STREAM_DATA帧，直到对等体接收到最终流偏移。端点可以安全地忽略它从对等端接收到的处于此状态的流的任何MAX_STREAM_DATA帧。 一旦成功确认了所有流数据，流的发送部分就进入Data Recvd状态，这是一种结束状态。 从任何Ready，Send或Data Sent状态，应用程序可以发信号通知它希望放弃流数据的传输。或者，端点可能从其对等端接收STOP_SENDING帧。在任何一种情况下，端点都会发送RESET_STREAM帧，这会导致流进入Reset Sent状态。 端点可以发送RESET_STREAM作为提及流的第一帧，这会导致该流的发送部分打开，然后立即转换到Reset Sent状态。 一旦确认了包含RESET_STREAM的分组，则流的发送部分进入Reset Recvd状态，这是终结状态。 3.2 接收流状态 图2显示了从对等方接收数据的流部分的状态。接收流的一部分的状态仅镜像对等体流的发送部分的一些状态。流的接收部分不跟踪发送部分上无法观察到的状态，例如Ready状态。相反，流的接收部分跟踪向应用程序传送数据，其中一些数据不能被发送者观察到。 12345678910111213141516171819202122232425262728293031 o | Recv STREAM / STREAM_DATA_BLOCKED / RESET_STREAM | Create Bidirectional Stream (Sending) | Recv MAX_STREAM_DATA / STOP_SENDING (Bidirectional) | Create Higher-Numbered Stream v+-------+| Recv | Recv RESET_STREAM| |-----------------------.+-------+ | | | | Recv STREAM + FIN | v |+-------+ || Size | Recv RESET_STREAM || Known |----------------------&gt;|+-------+ | | | | Recv All Data | v v+-------+ Recv RESET_STREAM +-------+| Data |--- (optional) ---&gt;| Reset || Recvd | Recv All Data | Recvd |+-------+&lt;-- (optional) ----+-------+ | | | App Read All Data | App Read RST v v+-------+ +-------+| Data | | Reset || Read | | Read |+-------+ +-------+ 当为该流接收到第一个STREAM，STREAM_DATA_BLOCKED或RESET_STREAM时，将创建由对等方发起的流的接收部分（客户端的类型1和3，或服务器的0和2）。对于由对等方发起的双向流，接收流的发送部分的MAX_STREAM_DATA或STOP_SENDING帧也会创建接收部分。流的接收部分的初始状态是Recv。 当端点发起的双向流的发送部分（客户端类型0，服务器类型1）进入Ready状态时，流的接收部分进入Recv状态。 当从该流的对等体收到MAX_STREAM_DATA或STOP_SENDING帧时，端点将打开双向流。为未打开的流接收MAX_STREAM_DATA帧表示远程对等体已打开流并提供流控制分数。为未打开的流接收STOP_SENDING帧表示远程对等体不再希望接收此流上的数据。如果数据包丢失或重新排序，则任何一个帧都可能在STREAM或STREAM_DATA_BLOCKED帧之前到达。 在创建流之前，必须创建具有较低编号的流ID的所有相同类型的流。这可确保流的创建顺序在两个端点上保持一致。 在“Recv”状态中，端点接收STREAM和STREAM_DATA_BLOCKED帧。传入的数据被缓冲，可以重新组合成正确的顺序以便传送到应用程序。当应用程序使用数据并且缓冲区空间可用时，端点发送MAX_STREAM_DATA帧以允许对等方发送更多数据。 当接收到具有FIN位的STREAM帧时，流的最终大小是已知的（参见第4.4节）。然后，流的接收部分进入Size Known状态。在此状态下，端点不再需要发送MAX_STREAM_DATA帧，它只接收流数据的任何重传。 一旦接收到流的所有数据，接收部分就进入Data Recvd状态。这可能是由于接收到导致转换为Size Known的相同STREAM帧而发生的。在此状态下，端点具有所有流数据。可以丢弃它为流接收的任何STREAM或STREAM_DATA_BLOCKED帧。 Data Recvd状态持续存在，直到流数据已传送到应用程序。一旦传送了流数据，流就进入Data Read状态，这是一种终结状态。 在Recv或Size Known状态下接收到RESET_STREAM帧会使流进入Reset Recvd状态。这可能导致流数据传递到应用程序中断。 当流处于Data Recvd状态接收到RESET_STREAM时，端点可能接收到所有流数据。类似地，在接收RESET_STREAM帧之后剩余的流数据可能到达（Reset Recvd状态）。一个实现可以自由选择管理这种情况。发送RESET_STREAM意味着端点无法保证流数据的传递。但是，如果收到RESET_STREAM，则不要求不传送流数据。实现可以中断流数据的传送，丢弃未使用的任何数据，并立即发出RESET_STREAM的接收信号。或者，如果流数据被完全接收并且缓冲以供应用程序读取，则可以抑制或保留RESET_STREAM信号。在后一种情况下，流的接收部分从Reset Recvd转换为Data Recvd。 一旦应用程序已经被传送指示流被重置的信号，流的接收部分就转换到Reset Recvd状态，这是终结状态。 3.3 允许的帧类型 流的发送方只发送三种帧类型，这些类型会影响发送方或接收方的流状态：STREAM（第19.8节），STREAM_DATA_BLOCKED（第19.13节）和RESET_STREAM（第19.4节）。 发送方不得从终结状态（Data Recvd或Reset Recvd）发送任何这些帧。发送者在发送RESET_STREAM后不得发送STREAM或STREAM_DATA_BLOCKED。也就是说，在终结状态和Reset Sent状态下。接收器可以在任何状态下接收这三个帧中的任何一个，因为可能延迟传送携带它们的分组。 流的接收器发送MAX_STREAM_DATA（第19.10节）和STOP_SENDING帧（第19.5节）。 接收器仅发送处于Recv状态的MAX_STREAM_DATA。接收器可以在没有收到RESET_STREAM帧的任何状态下发送STOP_SENDING;这是除Reset Recvd或Reset Read以外的状态。但是，在Data Recvd状态下发送STOP_SENDING帧几乎没有价值，因为已收到所有流数据。由于数据包的延迟传送，发送方可以在任何状态下接收这两个帧中的任何一个。 3.4 双向流状态 双向流由发送和接收部分组成。实现可以将双向流的状态表示为发送和接收流状态的组合。当发送或接收部分处于非终结状态时，最简单的模型将流呈现为open，而当发送和接收流都处于终结状态时，流呈现为closed。 表2显示了与HTTP/2 中的流状态松散对应的双向流状态的复杂映射。这表明发送或接收部分流的多个状态被映射到相同的复合状态。请注意，这只是这种映射的一种可能性;此映射要求在转换到closed或half-closed状态之前确认数据。 发送部分 接收部分 复合状态 No Stream/Ready No Stream/Recv *1 idle Ready/Send/Data Sent Recv/Size Known open Ready/Send/Data Sent Data Recvd/Data Read half-closed (remote) Ready/Send/Data Sent Reset Recvd/Reset Read half-closed (remote) Data Recvd Recv/Size Known half-closed (local) Reset Sent/Reset Recvd Recv/Size Known half-closed (local) Reset Sent/Reset Recvd Data Recvd/Data Read closed Reset Sent/Reset Recvd Reset Recvd/Reset Read closed Data Recvd Data Recvd/Data Read closed Data Recvd Reset Recvd/Reset Read closed 备注 (*1)：如果尚未创建流，则该流被认为是idle，或者如果流的接收部分处于“Recv”状态而尚未接收到任何帧，则该流被认为是idle。 3.5 询问状态过渡 如果端点不再对它在流上接收的数据感兴趣，它可以发送一个STOP_SENDING帧来标识该流，以提示在相反方向关闭流。这通常表示接收应用程序不再读取它从流中接收的数据，但不保证将忽略传入的数据。 发送STOP_SENDING后收到的STREAM帧仍计入连接和流量控制，即使这些帧在接收时将被丢弃。 STOP_SENDING帧请求接收端点发送RESET_STREAM帧。如果流处于就绪或发送状态，则接收STOP_SENDING帧的端点必须发送RESET_STREAM帧。如果流处于数据发送状态并且任何未完成的数据被声明丢失，则端点应该发送RESET_STREAM帧代替重传。 端点应该将错误代码从STOP_SENDING帧复制到它发送的RESET_STREAM帧，但是可以使用任何应用程序错误代码。发送STOP_SENDING帧的端点可以忽略它接收的任何RESET_STREAM帧中携带的错误代码。 如果在已经处于Data Sent状态的流上接收到STOP_SENDING帧，则希望停止在该流上重传先前发送的STREAM帧的端点必须首先发送RESET_STREAM帧。 STOP_SENDING应该仅针对未被对等方重置的流发送。 STOP_SENDING对于Recv或Size Known状态的流最有用。 如果包含先前STOP_SENDING的数据包丢失，则端点应发送另一个STOP_SENDING帧。但是，一旦为流接收到所有流数据或RESET_STREAM帧（即，流处于Recv或Size Known以外的任何状态）发送STOP_SENDING帧是不必要的。 希望终止双向流的两个方向的端点可以通过发送RESET_STREAM来终止一个方向，并且它可以通过发送STOP_SENDING帧来鼓励在相反方向上的快速终止。]]></content>
      <categories>
        <category>network</category>
        <category>quic</category>
      </categories>
      <tags>
        <tag>QUIC</tag>
        <tag>translate</tag>
        <tag>RFC</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QUIC协议翻译 - draft-ietf-quic-invariants-latest]]></title>
    <url>%2F2019%2F02%2F13%2Fnetwork%2Fquic%2Fdraft-ietf-quic-invariants-latest%2F</url>
    <content type="text"><![CDATA[本文是对QUIC协议IETF提案：draft-ietf-quic-invariants-latest的翻译。 draft-ietf-quic-invariants-latest是IETF的QUIC提案中的第一部分，包含了基础的QUIC的数据包形式，定义了QUIC各个版本之间不应该发生变化的内容，明确了什么样的协议属于QUIC协议，并为不同版本的QUIC协议的兼容提供支持。 Abstract 本文档定义了QUIC传输协议的属性，随着协议的新版本的开发，这些属性随时间保持不变。 1. 简介 除了提供安全的多路传输外，QUIC [QUIC-TRANSPORT]还包括协商版本的能力。这允许协议随着时间的推移而改变以响应新的要求。协议的许多特征将在不同版本之间变化。 本文档描述了QUIC的子集，旨在在开发和部署新版本时保持稳定。所有这些不变特性都是与IP版本无关的。 本文档的主要目标是确保可以部署新版本的QUIC。本文档记录了协议中无法变更的属性，旨在保留更改协议其他任何部分的能力。因此，除非在本文件中具体描述的内容，协议的任何方面都可以在不同版本之间发生改变。 附录A是根据QUIC版本1的知识可能做出的一些不正确假设的非详尽列表;这些不适用于每个版本的QUIC。 2. 公约和定义 略 3. QUIC的极其抽象的描述 QUIC是两个端点之间面向连接的协议。这些端点交换UDP数据报。UDP数据报中包含QUIC数据包。 QUIC端点使用QUIC数据包建立QUIC连接，这是这些端点之间的共享的协议状态。 4. QUIC数据包头 QUIC数据包是QUIC端点交换的UDP数据报的内容。本文档描述了这些数据报的具体内容。 QUIC定义了两种类型的包头：长和短。长包头的第一个字节的最高有效标志位被置1，短包头的该位置0。 除了此处描述的值之外，QUIC数据包的有效负载是特定于版本的并且具有任意长度。 4.1 长包头 长包头采用图1中描述的形式。具有特定于版本的语义的位标记为X. 123456789101112131415 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+|1|X X X X X X X|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Version (32) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|DCIL(4)|SCIL(4)|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Connection ID (0/32..144) ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Connection ID (0/32..144) ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 具有长报头的QUIC数据包将第一个字节的高位设置为1.该字节中的所有其他位都是特定于版本的。 接下来的四个字节包括一个32位版本字段（参见第4.4节）。 下一个字节包含后面两个连接ID（参见第4.3节）的字节长度。每个ID的长度编码为4位无符号整数。目标连接ID（DCIL）的长度占用字节的高位，源连接ID（SCIL）的长度占用字节的低位。编码长度为0表示连接ID的长度也为0字节。非零编码长度增加3以获得连接ID的全长;因此，最终值为0或长度为4到18个字节（包括端点）。例如，值为0xe0的字节描述17字节的目标连接ID和零字节的源连接ID。 连接ID长度后跟两个连接ID。分别是接收者相关联的连接ID（目的地连接ID）与发送者相关联的连接ID（源连接ID）。 数据包的其余部分包含特定于版本的内容。 4.2 短包头 短包头采用图2中描述的形式。具有特定于版本的语义的位标记为X. 123456789 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+|0|X X X X X X X|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Connection ID (*) ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 具有短报头的QUIC数据包将第一个字节的高位设置为0。 具有短报头的QUIC分组包括目的地连接ID。短标头不包括“连接ID长度”，“源连接ID”或“版本”字段。 数据包的其余部分具有特定于版本的语义。 4.3 连接ID 连接ID是任意长度的不透明字段。 连接ID的主要功能是确保较低协议层（UDP，IP和以下）的寻址更改不会导致QUIC连接的数据包传递到错误的端点。端点和支持它们的中介使用连接ID来确保每个QUIC数据包都可以传递到端点的正确实例。在端点处，连接ID用于标识数据包所针对的QUIC连接。 每个端点使用特定于版本的方法选择连接ID。相同QUIC连接的数据包可能使用不同的连接ID值。 4.4 版本 QUIC版本使用32位整数标识，以网络字节顺序编码。版本0保留用于版本协商（参见第5节）。所有其他版本号都可能有效。 本文档中描述的属性适用于所有版本的QUIC。不符合本文档中描述的属性的协议不是QUIC。未来的文档可能会描述适用于特定QUIC版本或一系列QUIC版本的其他属性。 5. 版本协商 QUIC端点接收具有长报头的数据包及其不理解或不支持的版本时，可能会发送版本协商数据包作为响应。具有短标头的数据包不会触发版本协商。 版本协商数据包设置第一个字节的高位，因此它符合第4.1节中定义的具有长标头的数据包的格式。 Version Negotiation数据包可由Version字段识别，该字段设置为0x00000000。 123456789101112131415161718192021 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+|1|X X X X X X X|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Version (32) = 0 |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|DCIL(4)|SCIL(4)|+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Connection ID (0/32..144) ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Connection ID (0/32..144) ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Supported Version 1 (32) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| [Supported Version 2 (32)] |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ...+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| [Supported Version N (32)] |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version Negotiation数据包包含一个Supported Version字段列表，每个字段标识发送数据包的端点支持的版本。 “支持的版本”字段遵循“版本”字段。版本协商数据包不包含其他字段。端点必须忽略不包含支持的版本字段或截断的支持版本的数据包。 版本协商数据包不使用完整性或机密性保护。特定的QUIC版本可能会将数据包作为其连接建立过程的一部分进行身份验证。 端点必须包含它在目标连接ID字段中接收的数据包的源连接ID字段中的值。源连接ID的值必须从接收数据包的目标连接ID复制，该数据最初由客户端随机选择。回复两个连接ID可以使客户端确信服务器已收到数据包，并且版本协商数据包不是由路径外攻击者生成的。 接收版本协商数据包的端点可能会更改它决定用于后续数据包的版本。端点更改QUIC版本的条件取决于它选择的QUIC版本。 有关如何支持QUIC版本1的端点生成和使用版本协商数据包的详细说明，请参见[QUIC-TRANSPORT]。 6.安全和隐私考量 中间件可能使用特定版本的QUIC的特征，并假设当其他版本的QUIC表现出相似的特征时，表达相同的底层语义。可能有许多这样的特征（见附录A）。已经做出一些努力来消除或掩盖QUIC版本1中的一些可观察特征，但其中许多仍然存在。其他QUIC版本可能会做出不同的设计决策，因此表现出不同的特征。 QUIC版本号不会出现在所有QUIC数据包中，这意味着可以根据特定于版本的特征从流中可靠地提取信息，这要求中间件为他们看到的每个连接ID保留状态。 本文档中描述的Version Negotiation数据包不受完整性保护;它只有适度的防止非路径攻击者插入的保护。 QUIC版本必须定义一种机制来验证它包含的值。]]></content>
      <categories>
        <category>network</category>
        <category>quic</category>
      </categories>
      <tags>
        <tag>QUIC</tag>
        <tag>translate</tag>
        <tag>RFC</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Strobe protocol framework分析 - Sponge Construction]]></title>
    <url>%2F2018%2F12%2F28%2Fcryptography%2FStrobe-Sponge%2F</url>
    <content type="text"><![CDATA[Strobe是一个面向物联网设计的密码学协议框架，目标是为了使加密协议更容易开发，部署，分析，并适用于微型物联网设备。在Strobe的设计中，仅使用了SHA-3中的块函数Keccak-f来对消息进行加密和验证。 Strobe利用了Keccak的海绵结构（Sponge Construction）来设计。这使得在Strobe的基础上，可以实现包括密码学哈希函数（Cryptographic hash function），消息认证码（Message authentication code）等机制；可以构建对称加密机制，数字签名机制（通过Schnorr Scheme），密钥交换机制（通过DH算法），以及TLS等类似的密码协议。 在这里将会分析Strobe协议的组成以及其原理，以及如何在Strobe上构建密码协议。 在分析Strobe协议之前，首先需要明确什么是海绵结构。 Strobe protocol framework - Sponge Construction 海绵结构（Sponge Construction）是Keccak提出的一种密码学函数。最开始的海绵结构是为构造密码学哈希函数所设计。后来发现通过海绵结构不仅仅适用于具有固定输出长度的密码学哈希函数，同样也适用于具有固定输入长度的流密码机制。 现有的的哈希函数可以将任意长度的输入映射为固定长度输出（实际上包括SHA2在内的密码学哈希函数也都做不到任意长度的输入，只不过是因为现有的密码学哈希函数可容纳的输入长度上限太大，近似的看作输入长度无限），而海绵结构则是可以将任意长度的输入映射为任意长度的输出。同时它的输出就像是一个随机数预言机（Random Oracle），能够保证输出的随机性。 Cryptographic Sponge Functions 说了这么多，到底什么是海绵结构呢？ 在密码学中的“海绵”，比较正式的说法应该是密码学海绵函数（Cryptographic Sponge Functions）。这个函数就像是一个海绵一样，能够不断，多次的输入来自外部的数据；同时也能够像挤海绵里的水一样，多次向外输出数据。不同于现实中的海绵，这里的海绵是可以无限的输入数据，也可以无限的输出数据。 海绵结构是一个简单的迭代的结构。构造一个海绵结构需要两个元素：一个长度为\(b\)的状态\(S\)（state），在状态上展开迭代过程；以及一个用于操作状态，输入和输入长度都为\(b\)的排列函数\(f\)。 实际上这里的函数\(f\)是一个纯函数，它接收状态作为传入，返回的是经过它处理后的状态。 而被传入函数\(f\)的状态\(S\)被分为两部分，分别是长度为\(r\)的公共部分\(R\)（rate），和长度为\(c\)的私有部分\(C\)（capacity）。 函数\(f\)的作用是根据现有的排列（permutation）来迭代产生新的排列。最新的SHA-3算法采用的同样是海绵结构，它采用的排列函数\(f\)是keccak-f[1600]。其中的1600代表这个函数的输入是1600位，输出同样是1600位。在Strobe中采用的排列函数\(f\)是keccak-f[b]，其中\(b\)是状态\(S\)的长度，根据keccak-f[b]的设计，\(b\)的取值只能是{200,400,800,1600}，长度单位是bit。 keccak算法 在keccak的处理过程中被分为两个过程，第一个部分是吸收过程，第二个部分是挤压过程。 吸收过程就是将输入的数据输入到海绵结构中。输入数据被填充后分割为多个块，每个块的长度与公共部分\(R\)的长度相同，之后不断的将这些块与状态\(S\)的公共部分\(R\)异或，每次异或后都调用排列函数\(f\)。 整个吸收过程是针对每一个输入数据块\(m_i\)执行如下算法： \[ (r,c) = f(r \oplus m_i,c) \] 吸收过程可以无限制的迭代下去，从这个角度来说，keccak可以吸收无限多的数据到状态中。 挤压过程就是从海绵结构中获得输出。当我们需要从海绵结构中获得输出时，我们从状态的公共部分读取输出，如果长度不够，那么可以利用\(f\)去修改状态，继续读取新的公共部分。这个过程可以不断的继续重复下去，直到读取到足够的输出为止。 这个过程就是现在SHA-3的算法的执行流程。得到的输出就是哈希值。 实际上这样的海绵结构不仅仅可以用于哈希函数中。由于输入输出长度可变的特性，当输入较长而输出较短的情况适用于HASH，MAC等场景；而当输入较短，输出较长的情况下适用于对称加密流密码的场景。在流密码的场景中，输入的时密钥与nonce值，输出的是密钥流。 Duplex construction 事实上，海绵结构不仅仅可以一次吸收，一次挤出，它可以不断的重复吸收挤压的过程。keccak team提供了一种可以不断交替输入输出数据的结构，被称为双工结构（Duplex construction）。在这种结构允许我们不断的输入，输出，输入，输出数据。这种结构带来了一种好处：每一时刻的输出会受到之前输入与输出的影响。这样的属性可以实现相同操作的副本一致性（transcript consistency），也就意味着当不同的副本执行相同的操作，各个副本所维护的海绵结构可以保持一致性。 Summary 这篇文章简单的介绍了keccak团队设计的海绵结构，以及它的工作方式。虽然keccak成为了最新的SHA-3算法标准，但是并不代表keccak只能当作哈希函数来使用。后续将会继续介绍基于keccak构造的密码学协议框架Strobe。]]></content>
      <categories>
        <category>cryptography</category>
      </categories>
      <tags>
        <tag>cryptography</tag>
        <tag>strobe protocol framework</tag>
        <tag>keccak</tag>
        <tag>SHA3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字签名机制 - ED25519]]></title>
    <url>%2F2018%2F12%2F28%2Fcryptography%2Fed25519%2F</url>
    <content type="text"><![CDATA[ED25519是一种EdDSA算法，是一种在扭曲爱德华兹曲线（Twisted Edwards curves）上使用Schnorr机制来实现的一种数字签名机制。它具有速度快，密钥较短，安全性高等优点。 数字签名机制 - Schnorr Scheme 数字签名机制- ED25519 本文中所有出现的变量，小写字母表示标量，即一个数字，在这里指整数；大写字母表示离散对数问题中的参数，例如：椭圆曲线中的点。 椭圆曲线密码学（ECC）是基于离散对数问题中的椭圆曲线而设计的。现行的ECC算法多用于替代RSA算法，以提升原始算法的安全性与性能。相比较RSA，ECC的性能较高，密钥长度较短，然而实现难度较大。在ECC算法基础上构建的数字签名算法被称为ECDSA算法，经过NIST批准的曲线有多条，例如secp256r1，secp256k1等。但现有的ECC算法中的曲线被指存在后门。 EdDSA从某种意义上来说也属于椭圆曲线密码学，不同的是它采用扭曲爱德华兹曲线作为椭圆曲线，同时采用的签名机制也不同于ECDSA算法。EdDSA的重要实现ED25519是Daniel J. Bernstein等人设计的EdDSA算法，采用的曲线参数完全公开，并说明了参数选取的意义，保证曲线中并未内置后门。同时ED25519采用Schnorr机制作为签名的构建方式，使得签名与验证的性能得到了巨大的提升。 ED25519算法 在现有的方案ED25519种，采用了将参数\(R\)，公钥 \(Y\)，与消息体 \(M\)进行哈希作为随机数 \(r_2\)。具体的ED25519公私钥生成与签名验证的方式如下： 公私钥生成 当前根据ED25519协议中密钥长度 \(b\)，被选择为\(256\)；生成元为 \(G\) ；哈希函数 \(H()\)为SHA512；\(M\)是被签名的信息；\(l\) 是一个质数，满足\(lG = 0\)。 随机选择一个长度为 \(b\) 为的二进制数作为私钥 \(a\)。 对 \(a\) 的进行哈希，产生一个长度为 \(2b\) 的值为 \(h = H(a)\)，其中 \(h_0 \ldots h_{b-1}\) 为\(x\)，用于产生公钥 ，\(h_b \dots h_{2b-1}\) 为随机数 \(k\) 。 将 \(x_0, x_1, x_2​\)置\(0​\)，\(x_{b-1}​\)置0，\(x_{b-2}​\)置1。 计算公钥 \(Y = xG\)。 其中 \(a\) 为私钥，\(Y\)为公钥。 签名流程 进行签名时，需要私钥 \(a\)，执行公私钥生成算法，得到公钥 \(Y\)，随机数 \(k\)。 计算随机数 \(r = H(k, M)\)。 计算随机点\(R = rG\)。 计算签名\(s = (r + H(R,Y,M)x ) \bmod l\)。 其中得到的\((R,s)\)便是得到的数字签名。 其中 \(s\) 相当于前文所述Schnorr签名方案中的 \(s\) ，\(r\) 相当于 \(r_1\) ，\(H(R,Y,M)\)相当于\(r_2\)。这里的哈希函数\(H()\)便充当了随机数预言机。 验证流程 进行验证时，验证者只需要知道公钥 \(Y\)，签名\((R,s)\)， 消息 \(M\) 即可验证签名过程是否正确。 验证\(sG = R + H(R,Y,M)Y\)是否成立，即可验证签名是否正确。 其中 \(s\) 相当于前文所述Schnorr签名方案中验证公式中的 \(s\) ，\(G\) 为生成元，\(H(R,Y,M)\)为 \(r_2\) ，其余部分一一对应。 安全考量 在ED25519的算法设计中，通过使用密码学哈希函数来代替伪随机数发生器，避免了签名算法的使用者因为采用的随机数生成器不够随机化而产生的安全问题。ED25519的实现除去私钥的生成之外，签名过程已经完全脱离对随机数发生器的依赖，避免了因为随机化问题而导致密钥的泄露与安全性问题。]]></content>
      <categories>
        <category>cryptography</category>
      </categories>
      <tags>
        <tag>cryptography</tag>
        <tag>schnorr scheme</tag>
        <tag>digital signature</tag>
        <tag>ED25519</tag>
        <tag>EdDSA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字签名机制 - Schnorr Scheme]]></title>
    <url>%2F2018%2F12%2F27%2Fcryptography%2FSchnorr-Scheme%2F</url>
    <content type="text"><![CDATA[Schnorr机制是一种基于离散对数难题的知识证明机制，由德国数学家和密码学家Claus-Peter Schnorr在1990年提出。这种知识证明机制具有实现简单，验证速度较快等优点。最开始是为Smart Card这样的资源受限设备而设计。 经过这些年的发展，在原始的Schnorr机制上实现了多种多样的改进与功能，实现了高性能的数字签名，以及包括环签名，门限签名等复杂签名机制。 在这里参考Schnorr的论文与其他的参考资料，分析Schnorr机制的原始机制与实现。并分析现在主流的EdDSA的实现ED25519，以及如何在Schnorr机制上建立的复杂签名机制。 数字签名机制 - Schnorr Scheme 数字签名机制- ED25519 本文中所有出现的变量，小写字母表示标量，即一个数字，在这里指整数；大写字母表示离散对数问题中的参数，例如：椭圆曲线中的点。 Original Schnorr Scheme 原始的Schnorr机制是一个交互式的机制。允许在任何拥有相同生成元（指在离散对数问题中）的协议参与者双方，证明某一方拥有私钥 \(x\) 而不需要直接交换它。其中双方都拥有的生成元设为 \(G\) ，证明者拥有私钥 \(x\) 。验证者从证明者处取得 \(Y\) ，其中 \(Y = xG\)，\(Y\) 即公钥。 Original Schnorr Signature的协议流程如下： 证明者随机选择一个标量 \(r_1\)，然后计算出 \(R = r_1G\)。并将 \(R\) 发送至验证者。 验证者回应一个随机的标量 \(r_2\)。 证明者回应一个标量\(s\)，通过公式 \(s = r_1 + r_2x\) 计算。 因为离散对数问题是困难的，因此验证者不会知道 \(x, r_1\)的值，验证者仅知道由 \(x, r_1\)计算得到的 \(Y, R\)。但是验证者可以通过以下计算来验证\(s\)是正确的： 由于\(s = r_1 + r_2x\)，等式两边同时添加相同的生成元可得 \(sG = r_1G + r_2xG\)。 由于\(R = r_1G\)，\(Y = xG\)，可以化简得到 \(sG = R + r_2Y\)。 其中 \(G\) 是生成元，双方都可知，\(R, Y, s, r_2\) 验证者都知道，所以验证者可以轻松验证化简过的公式。 这个过程是零知识的，因为验证者并不能得到私钥 \(x\) 的值，却可以通过计算与通讯的方式验证证明者确实拥有私钥 \(x\)。 Problem of Original Schnorr Scheme 然而这样交互式的过程，会导致验证者通过"fork"的方式获得私钥 \(x\)。验证者只需要简单的提供两个不同的随机值 \(r_2^1, r_2^2\)，并要求证明者计算 \(s_1 = r_1 + r_2^1x, s_2 = r_1 + r_2^2x\)，即可计算出\(x = (s_1 - s_2)/(r_2^1 - r_2^2)\)。这样一来，这个过程便无法公开的验证，因为一旦两个验证者相互串通，交换自己得到的值，便可以推出私钥\(x\)。 为了解决这个问题，后续将会通过对现有的协议进行Fiat–Shamir变换，使用Random oracles改造这个算法来使Schnorr原始的Schnorr Scheme变成可公开验证的非交互式算法。 Fiat–Shamir and Random oracles 上述原始Schnorr Scheme中存在的私钥泄露问题使得算法无法在公开的环境下使用。通过将原始的交互式协议转变为非交互式协议可以解决这个问题。 Fiat–Shamir变换是一种利用交互式零知识证明方案创建数字签名的方式。根据Fiat–Shamir变换，我们可以将原始方案中的证明者采用随机数预言机（Random oracle）来代替，利用这样的方式构造数字签名。 随机数预言机，即随机数函数，是一种针对任意输入得到的输出之间是项目独立切均匀分布的函数。理想的随机数预言机并不存在，在实现中，经常采用密码学哈希函数作为随机数预言机。 原本的设计中，Schnorr签名是一种交互式协议，需要一个实际存在的验证者与参与者，而根据Fiat-Shamir转换，可以将具体的验证者采用随机数预言机来代替。将验证者替换为随机数预言机后，外部的验证者便无法通过交换 \(r_2\)来推出私钥 \(x\) ，原本的 \(r_2\) 采用随机数预言机产生的随机数来表示。]]></content>
      <categories>
        <category>cryptography</category>
      </categories>
      <tags>
        <tag>cryptography</tag>
        <tag>schnorr scheme</tag>
        <tag>digital signature</tag>
        <tag>ED25519</tag>
        <tag>EdDSA</tag>
      </tags>
  </entry>
</search>
